1. Which is a key characteristic of Large Language Models (LLMs) without Retrieval Augmented Generation (RAG)?
a) They rely on internal knowledge learned during pretraining on a large text corpus. (*)
b) They cannot generate responses without fine-tuning.
c) They always use an external database for generating responses.
d) They use vector databases exclusively to produce answers.

2. What differentiates Semantic search from traditional keyword search?
a) It depends on the number of times keywords appear in the content.
b) It relies solely on matching exact keywords in the content.
c) It is based on the date and author of the content.
d) It involves understanding the intent and context of the search. (*)

3. What does the Ranker do in a text generation system?
a) It interacts with the user to understand the query better.
b) It generates the final text based on the user's query.
c) It evaluates and prioritizes the information retrieved by the Retriever. (*)
d) It sources information from databases to use in text generation.

4. What do embeddings in Large Language Models (LLMs) represent?
a) The frequency of each word or pixel in the data
b) The grammatical structure of sentences in the data
c) The color and size of the font in textual data
d) The semantic content of data in high-dimensional vectors (*)

5. What is the function of the Generator in a text generation system?
a) To collect user queries and convert them into database search terms
b) To store the generated responses for future use
c) To generate human-like text using the information retrieved and ranked, along with the user's original query (*)
d) To rank the information based on its relevance to the user's query

Solutions:
1) a
Explanation: Large Language Models (LLMs) without Retrieval Augmented Generation (RAG) primarily rely on internal knowledge learned during pretraining on a large text corpus.
              These models are trained on vast amounts of text data, which enables them to learn complex patterns, structures, and relationships within language.

2) d
Explanation: Semantic search differs from traditional keyword search in that it involves understanding the intent and context of the search query, rather than relying solely on matching exact keywords 
              in the content.

3) c 
Explanation: The Ranker in a text generation system evaluates and prioritizes the information retrieved by the Retriever. 
              After the Retriever sources relevant information from a large corpus or database, the Ranker assesses the retrieved information to determine its relevance, quality, 
              and suitability for the specific task or context. The Ranker may use various criteria and algorithms to evaluate the retrieved information, such as relevance to the user's query, 
              credibility of the source, recency of the information, and other contextual factors.
4) d
Explanation: Embeddings map words or text onto a continuous vector space where similar words are located close to each other. This allows NLP models to capture semantic relationships between words, 
              such as synonyms or related concepts. For example, in a well-trained embedding space, the vectors for "king" and "queen" would be closer to each other than to unrelated words such as "car" or "tree."

5) c
Explanation: The Generator in a text generation system is responsible for producing human-like text based on the information retrieved and ranked by the system, along with the user's original query or input. 
              After the relevant information has been sourced from external sources by the Retriever and evaluated by the Ranker, the Generator processes this information along with the user's query to generate 
              coherent and contextually appropriate text responses.
